{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM with 1D CNN\n"
      ],
      "metadata": {
        "id": "4dMrePNIjc9Y"
      },
      "id": "4dMrePNIjc9Y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount google drive"
      ],
      "metadata": {
        "id": "AwsGCNtxjiLk"
      },
      "id": "AwsGCNtxjiLk"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive          \n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiFk_0MMjsU_",
        "outputId": "1e7608a7-ff3d-4e2b-cd2a-f5732e126bbb"
      },
      "id": "aiFk_0MMjsU_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install libraries"
      ],
      "metadata": {
        "id": "yel83XRRjvgq"
      },
      "id": "yel83XRRjvgq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NR1j52vFxm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6d9313f-a6f0-4624-f5e1-8fdfe937d993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wfdb in /usr/local/lib/python3.8/dist-packages (4.1.0)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wfdb) (1.7.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from wfdb) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.10.1 in /usr/local/lib/python3.8/dist-packages (from wfdb) (1.21.6)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wfdb) (1.3.5)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.2.2 in /usr/local/lib/python3.8/dist-packages (from wfdb) (3.2.2)\n",
            "Requirement already satisfied: SoundFile<0.12.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from wfdb) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0.0,>=1.0.0->wfdb) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib<4.0.0,>=3.2.2->wfdb) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (2.10)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from SoundFile<0.12.0,>=0.10.0->wfdb) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->SoundFile<0.12.0,>=0.10.0->wfdb) (2.21)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install wfdb #install wfdb library on colab\n",
        "!pip install tqdm ##install tqdm library on colab\n",
        "!pip install seaborn\n"
      ],
      "id": "9NR1j52vFxm1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "mlL9bdWqjqs7"
      },
      "id": "mlL9bdWqjqs7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff7e942b"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import wfdb\n",
        "from wfdb import processing\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import normalize , LabelEncoder\n",
        "import os\n",
        "import math\n",
        "import random\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim \n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset,DataLoader,TensorDataset\n",
        "import torch.utils.data as data_utils\n",
        "import torchvision.transforms as transforms  \n"
      ],
      "id": "ff7e942b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set torch to CPU"
      ],
      "metadata": {
        "id": "sZ_tAmIvj2Es"
      },
      "id": "sZ_tAmIvj2Es"
    },
    {
      "cell_type": "code",
      "source": [
        "#set torch to CPU\n",
        "\n",
        "device = torch.device('cpu')\n"
      ],
      "metadata": {
        "id": "Mfe_vtWo5hoI"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Mfe_vtWo5hoI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGWMCgcyFwc1"
      },
      "source": [
        "Useful constants"
      ],
      "id": "UGWMCgcyFwc1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5-O9ufjgAPz"
      },
      "outputs": [],
      "source": [
        "train_files = [\n",
        "    \"a01\",\n",
        "    \"c01\",\n",
        "    \"b01\",\n",
        "    \"a02\",\n",
        "    \"c02\",\n",
        "    \"b02\",\n",
        "    \"a03\",\n",
        "    \"c03\",\n",
        "    \"b03\",\n",
        "    \"a04\",\n",
        "    \"c04\",\n",
        "    \"b04\",\n",
        "    \"a05\",\n",
        "    \"c05\",\n",
        "    \"a06\",\n",
        "    \"c06\",\n",
        "    \"a07\",\n",
        "    \"c07\",\n",
        "    \"a08\",\n",
        "    \"c08\",\n",
        "    \"a09\",\n",
        "    \"a10\",\n",
        "    \"a11\",\n",
        "    \"a12\",\n",
        "    \"a13\",\n",
        "    \"a14\",\n",
        "    \"a15\",\n",
        "    \"a16\",\n",
        "]\n",
        "\n",
        "test_files = [\"b05\", \"c09\", \"c10\", \"a17\", \"a18\", \"a19\", \"a20\"]\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/ML/Dataset/Apnea/apnea-ecg-database-1.0.0/\"  # path of dataset file\n"
      ],
      "id": "Z5-O9ufjgAPz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## defintion of bandpass filter"
      ],
      "metadata": {
        "id": "noA6mQuyDb8J"
      },
      "id": "noA6mQuyDb8J"
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import signal\n",
        "\n",
        "\n",
        "def bandpass_signal(xn, lower, upper):\n",
        "    length = len(xn)\n",
        "    t = np.linspace(-1, 1, length)\n",
        "\n",
        "    b, a = signal.butter(3, [lower, upper], btype=\"bandpass\", fs=100)\n",
        "\n",
        "    zi = signal.lfilter_zi(b, a)\n",
        "\n",
        "    z, _ = signal.lfilter(b, a, xn, zi=zi * xn[0])\n",
        "    z2, _ = signal.lfilter(b, a, z, zi=zi * z[0])\n",
        "    y = signal.filtfilt(b, a, xn)\n",
        "\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "AeijDCwPAJIC"
      },
      "id": "AeijDCwPAJIC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c61e75d"
      },
      "source": [
        "## Extract training , for LSTM we store each recording per subject in a dictionary which keys are the subject identifiers"
      ],
      "id": "7c61e75d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad684cc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "8db9de25-7e16-4dda-a785-1e207b97047c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-401c48f45146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mecg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mecg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mecg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mecg_with_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbandpass_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mecg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# store for subject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-5ed9e8cf984c>\u001b[0m in \u001b[0;36mbandpass_signal\u001b[0;34m(xn, lower, upper)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mxn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mz2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiltfilt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/signal/signaltools.py\u001b[0m in \u001b[0;36mlfilter\u001b[0;34m(b, a, x, axis, zi)\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msigtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linear_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2057\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msigtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linear_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "dictionnary_train_subjects = {}\n",
        "for idx, file in enumerate(train_files):\n",
        "    path_dat = os.path.join(path, file)\n",
        "    record = wfdb.rdrecord(path_dat, channels=[0])\n",
        "    apnea = wfdb.rdann(path_dat, \"apn\")\n",
        "    length = min(\n",
        "        len(apnea.symbol) - 1, math.floor(((record.p_signal.shape[0] - 3000) / 6000))\n",
        "    )\n",
        "    apnea_labels_per_subject = np.zeros((length))\n",
        "    ecg_readings_per_subject = np.zeros((length, 6000))\n",
        "    ecg = record.p_signal\n",
        "    ecg = ecg.reshape(len(ecg))\n",
        "    # filter\n",
        "    ecg_with_filter = bandpass_signal(ecg, 1, 48)\n",
        "    for j in range(length):\n",
        "        # store for subject\n",
        "        apnea_labels_per_subject[j] = 1 if apnea.symbol[j + 1] == \"A\" else 0\n",
        "        ecg_readings_per_subject[j] = ecg_with_filter[\n",
        "            3000 + (6000 * j) : 3000 + (6000 * (j + 1))\n",
        "        ]\n",
        "\n",
        "    ecg_readings_per_subject = np.array(ecg_readings_per_subject)\n",
        "    apnea_labels_per_subject = np.array(apnea_labels_per_subject)\n",
        "    # normalize add both labels and signals for each subject entry\n",
        "    dictionnary_train_subjects[idx] = [\n",
        "        normalize(ecg_readings_per_subject, norm=\"max\"),\n",
        "        apnea_labels_per_subject,\n",
        "    ]\n",
        "\n"
      ],
      "id": "ad684cc8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We do the same for the test set"
      ],
      "metadata": {
        "id": "I2hWeoPJkUNH"
      },
      "id": "I2hWeoPJkUNH"
    },
    {
      "cell_type": "code",
      "source": [
        "dictionnary_test_subjects = {}\n",
        "for idx, file in enumerate(test_files):\n",
        "    path_dat = os.path.join(path, file)\n",
        "    record = wfdb.rdrecord(path_dat, channels=[0])\n",
        "    apnea = wfdb.rdann(path_dat, \"apn\")\n",
        "    length = min(\n",
        "        len(apnea.symbol) - 1, math.floor(((record.p_signal.shape[0] - 3000) / 6000))\n",
        "    )\n",
        "    apnea_labels_per_subject = np.zeros((length))\n",
        "    ecg_readings_per_subject = np.zeros((length, 6000))\n",
        "    # ecg_with_filter = butter_bandpass_filter(record.p_signal, 1,48,fs = 100)\n",
        "    ecg = record.p_signal\n",
        "    ecg = ecg.reshape(len(ecg))\n",
        "    ecg_with_filter = bandpass_signal(ecg, 1, 48)\n",
        "    for j in range(length):\n",
        "        # store for subject\n",
        "        apnea_labels_per_subject[j] = 1 if apnea.symbol[j + 1] == \"A\" else 0\n",
        "        ecg_readings_per_subject[j] = ecg_with_filter[\n",
        "            3000 + (6000 * j) : 3000 + (6000 * (j + 1))\n",
        "        ]\n",
        "\n",
        "    ecg_readings_per_subject = np.array(ecg_readings_per_subject)\n",
        "    apnea_labels_per_subject = np.array(apnea_labels_per_subject)\n",
        "    dictionnary_test_subjects[idx] = [\n",
        "        normalize(ecg_readings_per_subject, norm=\"max\"),\n",
        "        apnea_labels_per_subject,\n",
        "    ]"
      ],
      "metadata": {
        "id": "ibY5vmd1F5tE"
      },
      "id": "ibY5vmd1F5tE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eI99bj-fF04S"
      },
      "id": "eI99bj-fF04S"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4myrlZFrGcBw"
      },
      "id": "4myrlZFrGcBw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataSet Class"
      ],
      "metadata": {
        "id": "VVFbjLqBFFqW"
      },
      "id": "VVFbjLqBFFqW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our Dataset class, as attributes it has one dictionary of subject with associated recordings and labels as attribute to store a mapping annotations and png filenames. We also store the sequence length of lstm as attribute.\n",
        "\n",
        "In the train set, to get one item, one retrieves a randomly chosen ordered sequence of 1 min segments of one subject, with associated labels. In the __getitem__ method the index oorresponds to the index of a subject. An epoch is therefore one iteration over all subjects.\n",
        "\n",
        "In the test set, the __getitem__ works similarly but we take the biggest number of sequences from one subjects in order, so not it's not random. This is necessary in order to calculate accuracy on the test set properly"
      ],
      "metadata": {
        "id": "sMm5zI5TldpC"
      },
      "id": "sMm5zI5TldpC"
    },
    {
      "cell_type": "code",
      "source": [
        "class Ecg_Per_Subject_DataSet(Dataset):\n",
        "    # dictionnary of \"userId\" a tuple of (ecg values) matrix and annotations\n",
        "    def __init__(self, dictionnary, sequence_length, transform=None):\n",
        "        self.dictionnary = dictionnary  # load data input and output from csv file\n",
        "        self.sequence_length = sequence_length\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dictionnary)  # return length of csv file\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        nb_minutes_for_subject = len(self.dictionnary[index][1])\n",
        "        starting_point = random.randint(\n",
        "            0, nb_minutes_for_subject - self.sequence_length\n",
        "        )\n",
        "\n",
        "        y_label_sequence = torch.tensor(\n",
        "            self.dictionnary[index][1][\n",
        "                starting_point : starting_point + self.sequence_length\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        y_label_sequence = y_label_sequence[:, None]\n",
        "        x_sequence = torch.tensor(\n",
        "            self.dictionnary[index][0][\n",
        "                starting_point : starting_point + self.sequence_length\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        return (x_sequence.unsqueeze(1), y_label_sequence)\n",
        "\n",
        "\n",
        "\n",
        "class Ecg_Per_Subject_Test_DataSet(Dataset):\n",
        "    # dictionnary of \"userId\" a tuple of (ecg values) matrix and annotations\n",
        "    def __init__(self, dictionnary, sequence_length, transform=None):\n",
        "        self.dictionnary = dictionnary  # load data input and output from csv file\n",
        "        self.sequence_length = sequence_length\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dictionnary)  # return length of csv file\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        nb_minutes_for_subject = len(self.dictionnary[index][1])\n",
        "        #the number of minutes should be a multiple of the sequence length\n",
        "        nb_used_minutes_for_subject = nb_minutes_for_subject - (\n",
        "            nb_minutes_for_subject % self.sequence_length\n",
        "        )\n",
        "        y_label_sequence = torch.tensor(\n",
        "            self.dictionnary[index][1][:nb_used_minutes_for_subject]\n",
        "        ).reshape(\n",
        "            (nb_used_minutes_for_subject // self.sequence_length, self.sequence_length)\n",
        "        )\n",
        "        #reshape to have separation between sequences\n",
        "        x_sequence = torch.tensor(\n",
        "            self.dictionnary[index][0][:nb_used_minutes_for_subject]\n",
        "        ).reshape(\n",
        "            (\n",
        "                nb_used_minutes_for_subject // self.sequence_length,\n",
        "                self.sequence_length,\n",
        "                -1,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return ((x_sequence.unsqueeze(2)), (y_label_sequence.unsqueeze(2)))\n",
        "   "
      ],
      "metadata": {
        "id": "f2-MTyM_81RN"
      },
      "id": "f2-MTyM_81RN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "mNkoq2oUHJn4"
      },
      "id": "mNkoq2oUHJn4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLlMpAiECuQ8"
      },
      "source": [
        "## Hyperparameters\n"
      ],
      "id": "SLlMpAiECuQ8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4qMVmlfC8CI"
      },
      "outputs": [],
      "source": [
        "in_channels = 1\n",
        "num_classes = 1\n",
        "learning_rate = 1e-4\n",
        "batch_size = 32\n",
        "num_epochs = 2000\n",
        "sequence_length = 10"
      ],
      "id": "M4qMVmlfC8CI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the loaders\n"
      ],
      "metadata": {
        "id": "4vQx8qFenSkt"
      },
      "id": "4vQx8qFenSkt"
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = Ecg_Per_Subject_DataSet(dictionnary_train_subjects, sequence_length)\n",
        "test_set = Ecg_Per_Subject_Test_DataSet(dictionnary_test_subjects, sequence_length)\n",
        "train_loader = DataLoader(dataset= train_set, batch_size = batch_size, shuffle =True)\n",
        "test_loader = DataLoader(dataset= test_set, batch_size = 1, shuffle =True)\n",
        "\n"
      ],
      "metadata": {
        "id": "csKWRLJxHUVf"
      },
      "id": "csKWRLJxHUVf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn0G11oGbu0i"
      },
      "source": [
        "# **Train model**"
      ],
      "id": "Zn0G11oGbu0i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAEPNJugT4XI"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_layers, hidden_size, in_channels=1, num_classes=1):\n",
        "        super(CNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.conv1 = nn.Conv1d(\n",
        "            in_channels=in_channels, out_channels=8, kernel_size=5, padding=2, stride=1\n",
        "        )\n",
        "        # convolution to extract features from data\n",
        "        self.pool1 = nn.MaxPool1d(kernel_size=6, stride=6)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(\n",
        "            in_channels=8, out_channels=16, kernel_size=5, padding=2, stride=1\n",
        "        )\n",
        "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(\n",
        "            in_channels=16, out_channels=32, kernel_size=7, padding=2, stride=1\n",
        "        )\n",
        "        self.conv4 = nn.Conv1d(\n",
        "            in_channels=32, out_channels=64, kernel_size=3, padding=2, stride=1\n",
        "        )\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=8000,\n",
        "            hidden_size=128,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=0.5,\n",
        "        )\n",
        "        self.fc1 = nn.Linear(256, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, L, channels, feature_sequence = x.size()\n",
        "\n",
        "        x = x.reshape(B * L, channels, feature_sequence)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = x.reshape((B, L, -1))\n",
        "\n",
        "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "        x, _ = self.lstm(x, (h0, c0))\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "\n",
        "        x = torch.sigmoid(self.fc4(x))\n",
        "\n",
        "        return x"
      ],
      "id": "KAEPNJugT4XI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8uZX9KuM5g_"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = CNN(1, 128,in_channels=in_channels, num_classes=num_classes).to(device)\n",
        "\n",
        "#loss and optimizer\n",
        "criterion =  nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "id": "Q8uZX9KuM5g_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9bFO9JeOlzC"
      },
      "source": [
        "## Train Network and calculate accuracy and loss"
      ],
      "id": "j9bFO9JeOlzC"
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "losses = []\n",
        "accur = []\n",
        "losses_test = []\n",
        "accur_test = []\n",
        "test_targets = []\n",
        "test_scores = []\n",
        "for epoch in range(num_epochs):\n",
        "    acc_test = 0\n",
        "    acc = 0\n",
        "    nb_iter_train = 0\n",
        "    nb_iter_test = 0\n",
        "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
        "        # Get data to cuda if possible\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "        data = data.float()\n",
        "        print(data.size())\n",
        "        targets = targets.float()\n",
        "        # forward\n",
        "\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "        # calculate accuracy and loss\n",
        "        targets_array = targets.reshape(-1, 1)\n",
        "        scores_array = (scores.reshape(-1, 1) > 0.5).float()  # astype('float32')\n",
        "        nb_iter_train += len(scores_array)\n",
        "        acc += (targets_array == scores_array).sum().item()\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()\n",
        "\n",
        "    # for test dataset\n",
        "    for batch_idx, (data_test, targets_test) in enumerate(tqdm(test_loader)):\n",
        "        # the batch size is the whole data for one subject\n",
        "        data_test = data_test[0]\n",
        "        targets_test = targets_test[0]\n",
        "        data_test = data.float()\n",
        "        targets_test = targets.float()\n",
        "        scores_test = model(data_test)\n",
        "\n",
        "        loss_test = criterion(scores_test, targets_test)\n",
        "        # calculate accuracy and loss\n",
        "        targets_array_test = targets_test.reshape(-1, 1)\n",
        "        # print(\"\\n scores_array_test \", scores_test.reshape (-1,1).size())\n",
        "        scores_array_test = (scores_test.reshape(-1, 1) > 0.5).float()\n",
        "        acc_test += (targets_array_test == scores_array_test).sum().item()\n",
        "        nb_iter_test += len(scores_array_test)\n",
        "        if epoch == num_epochs - 1:\n",
        "            for i in range(targets_array_test.shape[0]):\n",
        "                test_targets.append(int(targets_array_test[i][0]))\n",
        "                test_scores.append(int(scores_array_test[i][0]))\n",
        "    acc = acc / nb_iter_train\n",
        "    acc_test = acc_test / nb_iter_test\n",
        "    losses.append(loss)  # .detach().numpy())\n",
        "    accur.append(acc)\n",
        "    losses_test.append(loss_test)  # .detach().numpy())\n",
        "    accur_test.append(acc_test)\n",
        "    print(\n",
        "        \"\\n epoch {}\\tloss_train : {}\\t accuracy_train : {}%\".format(\n",
        "            epoch, loss, acc * 100\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"epoch {}\\tloss_test : {}\\t accuracy_test : {}%\\n\".format(\n",
        "            epoch, loss_test, acc_test * 100\n",
        "        )\n",
        "    )\n",
        "  "
      ],
      "metadata": {
        "id": "YG0NHLbMnjEy"
      },
      "execution_count": null,
      "outputs": [],
      "id": "YG0NHLbMnjEy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "73rmV1sLoiNI"
      },
      "id": "73rmV1sLoiNI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function returns the true_positives, false_positives, true_negatives, false_negatives"
      ],
      "metadata": {
        "id": "-r0cBDpHogbL"
      },
      "id": "-r0cBDpHogbL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CZkq7XdMfvN"
      },
      "outputs": [],
      "source": [
        "def confusion(prediction, truth):\n",
        "    \"\"\" Returns the confusion matrix for the values in the `prediction` and `truth`\n",
        "    tensors, i.e. the amount of positions where the values of `prediction`\n",
        "    and `truth` are\n",
        "    - 1 and 1 (True Positive)\n",
        "    - 1 and 0 (False Positive)\n",
        "    - 0 and 0 (True Negative)\n",
        "    - 0 and 1 (False Negative)\n",
        "    \"\"\"\n",
        "    confusion_vector = prediction / truth\n",
        "    # Element-wise division of the 2 tensors returns a new tensor which holds a\n",
        "    # unique value for each case:\n",
        "    #   1     where prediction and truth are 1 (True Positive)\n",
        "    #   inf   where prediction is 1 and truth is 0 (False Positive)\n",
        "    #   nan   where prediction and truth are 0 (True Negative)\n",
        "    #   0     where prediction is 0 and truth is 1 (False Negative)\n",
        "\n",
        "    true_positives = torch.sum(confusion_vector == 1).item()\n",
        "    false_positives = torch.sum(confusion_vector == float('inf')).item()\n",
        "    true_negatives = torch.sum(torch.isnan(confusion_vector)).item()\n",
        "    false_negatives = torch.sum(confusion_vector == 0).item()\n",
        "\n",
        "    return true_positives, false_positives, true_negatives, false_negatives"
      ],
      "id": "3CZkq7XdMfvN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function iterates through the test_loader, and calculates the different useful metrics: sensitivity, specificity, F1, Youden's index and accuracy. It also generates a confusion matrix using seaborn."
      ],
      "metadata": {
        "id": "fAyLIooko1cM"
      },
      "id": "fAyLIooko1cM"
    },
    {
      "cell_type": "code",
      "source": [
        "def check_test_accuracy(model):\n",
        "    model.eval()\n",
        "    accuracy = 0.0\n",
        "    total = 0.0\n",
        "    print(\"Checking accuracy on test data\")\n",
        "    with torch.no_grad():\n",
        "        true_positives, false_positives, true_negatives, false_negatives = 0, 0, 0, 0\n",
        "        predicted_tot = torch.zeros(0)\n",
        "        labels_tot = torch.zeros(0)\n",
        "\n",
        "        for data in test_loader:\n",
        "            segments, labels = data\n",
        "            # take only one batch\n",
        "            segments = segments[0]\n",
        "            # take onle one batch\n",
        "            labels = labels[0]\n",
        "            B, L, _, _ = segments.size()\n",
        "            labels = labels.reshape(B * L, -1)\n",
        "            # run the model on the test set to predict labels\n",
        "            segments = segments.float()\n",
        "            outputs = model(segments)\n",
        "\n",
        "            predicted = torch.round(outputs)\n",
        "\n",
        "            # reshape for confusion computations\n",
        "\n",
        "            predicted = predicted.reshape(B * L, -1)\n",
        "            labels = labels.reshape(B * L, -1)\n",
        "\n",
        "            tp, fp, tn, fn = confusion(predicted, labels)\n",
        "\n",
        "            true_positives += tp\n",
        "            false_positives += fp\n",
        "            true_negatives += tn\n",
        "            false_negatives += fn\n",
        "\n",
        "            total += labels.size(0)\n",
        "            accuracy += (predicted == labels).sum().item()\n",
        "\n",
        "        # compute the accuracy over all test segment\n",
        "        accuracy = 100 * accuracy / total\n",
        "        print(f\"Got {accuracy} accuracy \")\n",
        "\n",
        "        sensitivity = true_positives / (true_positives + false_negatives)\n",
        "        specificity = true_negatives / (true_negatives + false_positives)\n",
        "        precision = true_positives / (true_positives + false_positives)\n",
        "        recall = true_positives / (true_positives + false_negatives)\n",
        "        F1 = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "        print(f\"Sensitivity: {sensitivity}\")\n",
        "        print(f\"Specificity: {specificity}\")\n",
        "        print(f\"F1: {F1}\")\n",
        "        print(f\"Youden's index: {sensitivity + specificity - 1 }\")\n",
        "\n",
        "        # Plot confusion matrix\n",
        "\n",
        "        cm = [[true_positives, false_negatives], [false_positives, true_negatives]]\n",
        "\n",
        "        ax = plt.subplot()\n",
        "        sns.heatmap(cm, annot=True, fmt=\"g\", cmap=\"Greens\", ax=ax)\n",
        "        # annot=True to annotate cells, ftm='g' to disable scientific notation\n",
        "\n",
        "        # labels, title and ticks\n",
        "        ax.set_xlabel(\"Predicted labels\")\n",
        "        ax.set_ylabel(\"True labels\")\n",
        "        # ax.set_title('Confusion Matrix');\n",
        "        ax.xaxis.set_ticklabels([\"apnea\", \"normal\"])\n",
        "        ax.yaxis.set_ticklabels([\"apnea\", \"normal\"])\n",
        "\n",
        "\n",
        "check_test_accuracy(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "EIlIeuUVKGW0",
        "outputId": "f37ec0ce-d460-4281-deb0-62b9485df62f"
      },
      "id": "EIlIeuUVKGW0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking accuracy on test data\n",
            "Got 61.55487804878049 accuracy \n",
            "Sensitivity: 0.44282029234737746\n",
            "Specificity: 0.7104393008974964\n",
            "F1: 0.44958533391532085\n",
            "Youden's index: 0.15325959324487393\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LqGkDn3Q6zSL"
      },
      "id": "LqGkDn3Q6zSL",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}